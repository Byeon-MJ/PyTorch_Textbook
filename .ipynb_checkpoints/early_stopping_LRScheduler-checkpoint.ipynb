{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3758df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "matplotlib.style.use('ggplot')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e14008a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 전처리\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d25cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 가져오기\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=r'../PyTorch_Textbook_dataset/Hotdog_notHotdog/train',\n",
    "    transform=train_transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    root=r'../PyTorch_Textbook_dataset/Hotdog_notHotdog/test',\n",
    "    transform=val_transform)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7577cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "def resnet50(pretrained=True, requires_grad=False):\n",
    "    model = models.resnet50(progress=True, pretrained=pretrained)\n",
    "    if requires_grad == False:           # 파라미터를 고정하여 backward() 중에 기울기가 계산되지 않도록 함\n",
    "        for param in model.parameters(): # requires_grad=False를 파라미터로 받았기 때문에 해당 구문이 실행\n",
    "            param.requires_grad = False\n",
    "    elif requires_grad == True:         # 파라미터 값이 backward() 중에 기울기 계산에 반영\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    model.fc = nn.Linear(2048, 2)        # 마지막 분류를 위한 계층은 학습을 진행\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f48f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 감소\n",
    "# 'patience' 횟수만큼 검증 데이터셋에 대한 오차 감소가 없으면\n",
    "# 주어진 'factor'만큼 학습률을 감소\n",
    "class LRScheduler():\n",
    "    def __init__(self, optimizer, patience=5, min_lr=1e-6, factor=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.factor = factor\n",
    "        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            patience=self.patience,\n",
    "            factor=self.factor,\n",
    "            min_lr=self.min_lr,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        self.lr_scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ad1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조기 종료\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=5, verbose=False, delta=0,\n",
    "                path='../PyTorch_Textbook_dataset/Data/checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None # 검증 데이터에 대한 오차 최적화 값(오차가 가장 낮은 값)\n",
    "        self.early_stop = False # 조기 종료를 의미하며 초기값은 False로 설정\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path # 모델이 저장될 경로\n",
    "    \n",
    "    def __call__(self, val_loss, model):\n",
    "        '''\n",
    "        epoch만큼 학습이 반복되면서 best_loss가 갱신되고, \n",
    "        best_loss에 진전이 없으면 조기 종료한 후 모델을 저장\n",
    "        '''\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "            \n",
    "    def save_checkpoint(self, val_loss, model): # 검증 데이터셋에 대한 오차가 감소하면 모델을 저장\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f4a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
